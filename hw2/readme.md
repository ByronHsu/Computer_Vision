#  Computer Vision HW2 Report

> B05901011 é›»æ©Ÿä¸‰ è¨±ç§‰å€«

### Problem 1

1. Assume ğ‘‹ is a continuous random variable that denotes the estimated probability of a binary classifier. The instance is classified as positive if ğ‘‹ > ğ‘‡ and negative otherwise. When the instance is positive, ğ‘‹ follows a PDF ğ‘“1(ğ‘¥). When the instance is negative, ğ‘‹ follows a PDF ğ‘“2(ğ‘¥). Please specify which regions (A ~ E) represent the cases of False Positive and False Negative, respectively. Clearly explain why.

   <img src="problem/assets/p1-1.png" width="300px"/>

   - False Positive: B + Cå€ã€‚å‡æ­£ï¼Œè¢«æ¨¡å‹é æ¸¬ç‚ºæ­£çš„è² æ¨£æœ¬
   - False Negative: Eå€ã€‚å‡è² ï¼Œè¢«æ¨¡å‹é æ¸¬ç‚ºè² çš„æ­£æ¨£æœ¬ 

2. There are three ROC curves in the plot below. Please specify which ROC curves are considered to have reasonable discriminating ability, and which are not. Also, please answer that under what circumstances will the ROC curve fall on curve (b)?

   <img src="problem/assets/p1-2.png" width="300px"/>

   - a, bç‚ºåˆç†çš„æ›²ç·šï¼Œå› ç‚ºP_Dä»£è¡¨çš„æ˜¯True Positive, P_FAä»£è¡¨çš„æ˜¯False Positiveï¼Œç›´è§€çš„ä¾†çœ‹ï¼Œä¸ç®¡é‚Šç•Œæ€éº¼ç§»å‹•ï¼ŒP_Då¿…å®šå¤§æ–¼P_FA
   - ç•¶å…©ç¨®åˆ†å¸ƒå®Œå…¨é‡ç–Šæ™‚ï¼ŒROCæœƒè½åœ¨bæ›²ç·š

## Problem 2

#### 1. PCA

> In this task, you need to implement PCA from scratch, which means you cannot call PCA function directly from existing packages.

1. Perform PCA on the training data. Plot the mean face and the first five eigenfaces and show them in the report.

   |                  Mean                   |                     E1                     |                     E2                     |                     E3                     |                     E4                     |                     E5                     |
   | :-------------------------------------: | :----------------------------------------: | :----------------------------------------: | :----------------------------------------: | :----------------------------------------: | :----------------------------------------: |
   | <img src = "hw2-2_output/meanface.png"> | <img src = "hw2-2_output/eigenface-0.png"> | <img src = "hw2-2_output/eigenface-1.png"> | <img src = "hw2-2_output/eigenface-2.png"> | <img src = "hw2-2_output/eigenface-3.png"> | <img src = "hw2-2_output/eigenface-4.png"> |

2. Take ğ’‘ğ’†ğ’“ğ’”ğ’ğ’8_ ğ’Šğ’ğ’‚ğ’ˆğ’†6, and project it onto the above PCA eigenspace. Reconstruct this image using the first n = { 5, 50, 150, all } eigenfaces. For each n, compute the mean square error (MSE) between the reconstructed face image and the original ğ’‘ğ’†ğ’“ğ’”ğ’ğ’8_ ğ’Šğ’ğ’‚ğ’ˆğ’†6. Plot these reconstructed images with the corresponding MSE values in the report.

   | n    | MSE   | Reconstructed                                  |
   | ---- | ----- | ---------------------------------------------- |
   | 5    | 693.7 | <img src = "hw2-2_output/8_6-n=5.png">   |
   | 50   | 119.2 | <img src = "hw2-2_output/8_6-n=50.png">  |
   | 150  | 40.40 | <img src = "hw2-2_output/8_6-n=150.png"> |
   | 279  | 8.42  | <img src = "hw2-2_output/8_6-n=279.png"> |

3. Reduce the dimension of the image in testing set to dim = 100. Use t-SNE to visualize the distribution of test images.

<img src = "hw2-2_output/PCA-scattering.png" width="500px">

#### 2. LDA

   > In this task, you need to implement LDA from scratch, which means you cannot call LDA function directly from existing packages.

   1. Implement LDA and plot first 5 Fisherfaces.

      | F1                                                | F2                                                | F3                                                | F4                                                | F5                                                |
      | ------------------------------------------------- | ------------------------------------------------- | ------------------------------------------------- | ------------------------------------------------- | ------------------------------------------------- |
      | <img src = "hw2-2_output/fisherface-0.png"> | <img src = "hw2-2_output/fisherface-1.png"> | <img src = "hw2-2_output/fisherface-2.png"> | <img src = "hw2-2_output/fisherface-3.png"> | <img src = "hw2-2_output/fisherface-4.png"> |

   2. Use t-SNE to visualize the distribution of the projected testing data, which has the dimension of 30.

      <img src = "hw2-2_output/LDA-scattering.png" width="500px">

#### 3. KNN

> To apply the k-nearest neighbors (k-NN) classifier to recognize the testing set images, please determine the best k and n values by 3-fold cross-validation. 
>
> For simplicity, the choices for such hyper-parameters are:
>
> k = {1, 3, 5} and n = {3, 10, 39}.
>
> Please show the cross-validation results and explain your choice for (k, n). Also, show the recognition rate on the testing set using your hyper-parameter choice. Please apply the above comparing method on both PCA and LDA.
>
> Do you observe an improved recognition rate using fisherfaces (compared to eigenfaces obtained by PCA)? If so (or if not), what might be the possible explanation?



1. PCA

   é¸æ“‡åœ¨training setä¸Šè¡¨ç¾æœ€å¥½çš„(n, k) = (39, 1)ä¾†ä½œtestingï¼Œtestingçµæœä¹Ÿæ˜¯æœ€å¥½

   | n\k  |                         1                          |                         3                          |                         5                          |
   | :--: | :------------------------------------------------: | :------------------------------------------------: | :------------------------------------------------: |
   |  3   | Validation Acc : 0.66526<br/>Testing Acc : 0.58333 | Validation Acc : 0.64244<br/>Testing Acc : 0.53333 | Validation Acc : 0.48077<br/>Testing Acc : 0.48333 |
   |  10  | Validation Acc : 0.88828<br/>Testing Acc : 0.94167 | Validation Acc : 0.67460<br/>Testing Acc : 0.85000 | Validation Acc : 0.61451<br/>Testing Acc : 0.77500 |
   |  39  | Validation Acc : 0.92685<br/>Testing Acc : 0.95833 | Validation Acc : 0.83170<br/>Testing Acc : 0.93333 | Validation Acc : 0.74098<br/>Testing Acc : 0.90833 |

2. LDA

    LDAçš„validationéå¸¸å¥‡æ€ªï¼Œæ­£ç¢ºç‡é«˜åˆ°ä¸å¤ªåˆç†ï¼Œæˆ‘æƒ³äº†éå¸¸ä¹…ï¼Œæ‰ç™¼ç¾æ‡‰è©²æ˜¯å› ç‚ºæˆ‘å€‘å·²ç¶“æ‹¿validé‚£å¡Šdataå»ä½œldaäº†ï¼Œå› æ­¤åœ¨validationæ™‚æœƒæœ‰overfitçš„ç‹€æ³ç™¼ç”Ÿã€‚

   é€™çµ„åƒæ•¸è‹¥é¸æ“‡æ­£ç¢ºç‡æœ€é«˜çš„(3, 1), (10, 1), (39, 1)çš„è©±ï¼Œåœ¨testingçš„çµæœå¾ˆå¯èƒ½å£æ‰ã€‚

| n\k  |                         1                          |                         3                          |                         5                          |
| :--: | :------------------------------------------------: | :------------------------------------------------: | :------------------------------------------------: |
|  3   | Validation Acc : 1.00000<br/>Testing Acc : 0.29167 | Validation Acc : 0.95789<br/>Testing Acc : 0.29167 | Validation Acc : 0.83072<br/>Testing Acc : 0.29167 |
|  10  | Validation Acc : 1.00000<br/>Testing Acc : 0.79167 | Validation Acc : 0.97872<br/>Testing Acc : 0.80000 | Validation Acc : 0.92791<br/>Testing Acc : 0.79167 |
|  39  | Validation Acc : 1.00000<br/>Testing Acc : 0.91667 | Validation Acc : 0.97333<br/>Testing Acc : 0.90833 | Validation Acc : 0.89646<br/>Testing Acc : 0.91667 |



3. **Observation**: ç›´è¦ºä¾†è¬›ldaå› ç‚ºæœ‰è€ƒæ…®é€²å»åˆ†ç¾¤çš„æ¦‚å¿µï¼Œtesting setä¸Šçš„accæ‡‰ç•¶è¦æ¯”è¼ƒé«˜ï¼Œä½†åœ¨æˆ‘çš„å¯¦é©—ä¸­ï¼Œæ²’æœ‰é€™å€‹ç¾è±¡ï¼Œå¯èƒ½åŸå› æ¨æ¸¬æ˜¯è¨“ç·´è³‡æ–™ä¸å¤ å¤šï¼Œä¸è¶³ä»¥fitå‡ºä¸€å€‹å¥½çš„lda

## Problem3

1. Build a CNN model and train it on the given dataset. Show the architecture of your model in the report.

   <img src="problem/assets/p3-1.png"/>

   æˆ‘ä½¿ç”¨lenet5ç•¶ä½œmodelï¼Œä¸¦åœ¨å…¶ä¸­åŠ å…¥ä¸€äº›``Relu()``

2. Report your training / validation accuracy, and plot the learning curve (loss, accuracy) of the training process.

   <img src="hw2-3_output/learning-curve.png" width="500px"/>

   - Validation - Avg Loss: 1.51086, Accuracy: 0.98580
   - Training - Avg Loss: 1.47237, Accuracy: 0.99412

3. Visualize at least 6 filters on both the first and the last convolutional layers.

   | layer\filter | 0                                  | 1                                  | 2                                  | 3                                  | 4                                  | 5                                  |
   | ------------ | ---------------------------------- | ---------------------------------- | ---------------------------------- | ---------------------------------- | ---------------------------------- | ---------------------------------- |
   | C1           | <img src="hw2-3_output/0-0.png" /> | <img src="hw2-3_output/0-1.png" /> | <img src="hw2-3_output/0-2.png" /> | <img src="hw2-3_output/0-3.png" /> | <img src="hw2-3_output/0-4.png" /> | <img src="hw2-3_output/0-5.png" /> |
   | C5           | <img src="hw2-3_output/3-0.png" /> | <img src="hw2-3_output/3-1.png" /> | <img src="hw2-3_output/3-2.png" /> | <img src="hw2-3_output/3-3.png" /> | <img src="hw2-3_output/3-4.png" /> | <img src="hw2-3_output/3-5.png" /> |

   ç”±æ­¤å¯è¦‹ï¼Œå¾Œå±¤çš„conv layerï¼Œå·²ç¶“å¯è­˜åˆ¥å‡ºä¸€äº›é¡ä¼¼å¹¾ä½•ã€ç°¡å–®ç­†ç•«çš„åœ–å½¢

4. Visualize high-level and low-level features of 1000 validation data (100 for each class) extracted from different layers, and explain what you have observed from the two t-SNE plots.

   | Low-level(C1 layer)                               | High-level(S4 layer)                               |
   | ------------------------------------------------- | -------------------------------------------------- |
   | <img src="hw2-3_output/Low-Level-Features.png" /> | <img src="hw2-3_output/High-Level-Features.png" /> |

   ç”±ä¸Šåœ–æ¯”è¼ƒå¯ç™¼ç¾ï¼Œåœ¨high-levelæ™‚è³‡æ–™åˆ†ç¾¤æ•ˆæœæ˜é¡¯æ¯”low-levelå¥½å¾ˆå¤šï¼ŒåŸå› æ˜¯è¶Šåˆ°å¾Œå±¤ï¼Œinputçš„featureæ›´è¢«å½°é¡¯å‡ºä¾†ï¼Œå°‡è³‡æ–™åˆ†çš„æ›´é–‹ã€‚